# Команда 22
## Муштаков Макар и Ли Андрей
### tg: @senkhuu и @sacai52

# Информация перед оцениванием работ task1 и task2
Изначально были успешно сделаны task1 и task2, все было идеально и было проверено локально. Но как только начал делать task3 (естественно я создал новые файлы нужные только для task3, но и поменял уже имеющиеся файлы) и видимо после запуска каких-то файлов что-то произошло с узлом nn, и скорость скачивания hadoop на него сильно уменьшилась и из-за этого алгоритм развертывания hdfs начал выдавать ошибку даже, когда я решил перепроверить работы task1 и task2! В общем из-за этого полетели первые две задачи, в итоге решением было просто увеличть timeout (я оставил его без ограничений), в целом убрал пару ненужных функций с playbook для hdfs и вроде бы минут 15 работало и результат был удовлетворительный, НО в итоге помогло решение разделить задачи playbook на две части, отдельным файлом сделать очистку данных от предыдущих запусков и оставить deploy_hdfs чисто для развертывания. В итоге это помогло и теперь все работает стабильно!

