

# Практическое задание №1

Автоматизированное развертывание Hadoop HDFS кластера с 3 DataNode, NameNode и Secondary NameNode.

## Предисловие

В изначальной версии этого задания  `reset.yml` не было, но его функционал был встроен в playbook. Создание отдельного файла для разделения задач помогло повысить скорость работы алгоритма!

## Инструкция по использованию

1. Предварительные требования

На вашей машине должны быть установлены:

Для Linux
```bash
sudo apt update
sudo apt install -y ansible sshpass
```

Для macOS
```bash
brew install ansible
brew install hudochenkov/sshpass/sshpass
```

2. Клонируйте репозиторий и перейдите в нужную папку:
```bash
git clone https://github.com/Makaronaaaa/hse_data_platforms.git
cd hse_data_platforms/task1
```

3. Настройте файл `inventory.ini`:
- Замените YourPassword на пароль выданный для team-22
```bash
ansible_ssh_pass=YourPassword
ansible_become_pass=YourPassword
```

4. Выполните очистку и запустите развертывание:

При необходимости очистите данные оставшиеся после прошлых запусков (рекомендуется)
```bash
ansible-playbook reset.yml
```

Запустите развертывание
```bash

ansible-playbook deploy_hdfs.yml
```

## Как увидеть результат

### Веб-интерфейс

5. Откройте новое окно терминала и подключитесь к узлу
```bash
ssh -L 9870:192.168.1.91:9870 team@176.109.91.43
```
Откройте в браузере: `http://localhost:9870`

Вы должны увидеть 3 live nodes и 0 dead nodes

### Командная строка
6. Откройте новое окно терминала и подключитесь к NameNode
```bash
ssh team@176.109.91.43
ssh team@192.168.1.91

sudo -u hadoop /home/hadoop/hadoop/bin/hdfs dfsadmin -report

#Ожидаемый вывод 
Live datanodes (3)
```

## Архитектура кластера

- **team-22-nn** : NameNode + DataNode + Secondary NameNode
- **team-22-dn-00**: DataNode
- **team-22-dn-01** : DataNode


## Особенности решения

1. **Полная автоматизация** - одна команда `ansible-playbook deploy_hdfs.yml` для всего (на самом деле в новой версии две команды)
2. **Идемпотентность** - можно запускать многократно, старые данные очищаются автоматически
3. **Безопасное подключение** - через jump-сервер 176.109.91.43
4. **Автоматическая настройка SSH** - ключи генерируются и распространяются автоматически
5. **NameNode как DataNode** - чтобы получить 3 DataNode при ограниченном количестве узлов


## Что делает reset.yml и deploy_hdfs.yml

Playbook выполняет развертывание кластера в 6 этапов:

### 1. Очистка существующей установки
- Останавливает все запущенные Hadoop сервисы (NameNode, DataNode, Secondary NameNode)
- Удаляет оставшиеся Java-процессы пользователя hadoop
- Полностью удаляет предыдущую установку Hadoop и все данные HDFS
- Удаляет скачанные архивы Hadoop

### 2. Подготовка системы
- Создает системного пользователя `hadoop` на всех узлах
- Создает директорию `.ssh` для пользователя hadoop с правильными правами доступа
- Обновляет файл `/etc/hosts` на всех узлах, добавляя записи для всех узлов кластера (team-22-nn, team-22-dn-00, team-22-dn-01)

### 3. Настройка SSH доступа
- Генерирует SSH RSA ключ на NameNode (только на узле team-22-nn)
- Копирует публичный ключ NameNode на все остальные узлы
- Настраивает авторизованные ключи для пользователя hadoop на всех узлах
- **Результат:** пользователь hadoop может подключаться по SSH между всеми узлами без пароля

### 4. Установка и конфигурация Hadoop
Скачивает архив Hadoop 3.3.6 с официального сайта Apache на каждый узел
- Распаковывает архив в `/home/hadoop/hadoop-3.3.6`
- Создает символьную ссылку `/home/hadoop/hadoop` для удобства
- Настраивает переменную `JAVA_HOME` в файле `hadoop-env.sh`
- Создает директории для данных: `/home/hadoop/hadoop_data/namenode` и `/home/hadoop/hadoop_data/datanode`
- Развертывает конфигурационные файлы HDFS:
  - `core-site.xml` - указывает NameNode как точку входа (`hdfs://team-22-nn:9000`)
  - `hdfs-site.xml` - настраивает репликацию (3 копии) и пути к данным
  - `workers` - список DataNode узлов (team-22-nn, team-22-dn-00, team-22-dn-01)
- Добавляет переменные окружения Hadoop в `.bashrc` пользователя hadoop

### 5. Запуск сервисов
- Форматирует NameNode (если нужно)
- Запускает NameNode, Secondary NameNode и DataNode

### 6. Проверка
- Проверяет что все узлы зарегистрировались
- Выводит статус кластера


**Ключевой результат:** после выполнения playbook запускается полностью рабочий HDFS кластер:
- 3 Live Nodes
- Статус "Normal" у всех узлов
- Без ошибок и предупреждений

